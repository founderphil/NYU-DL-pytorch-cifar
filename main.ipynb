{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse"
      ],
      "metadata": {
        "id": "R2OOtXhbCBKG"
      },
      "id": "R2OOtXhbCBKG",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrrWXjYcLU3z",
        "outputId": "b0792794-c56b-480f-aa21-aa18328b2ffd"
      },
      "id": "YrrWXjYcLU3z",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr  3 22:45:49 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBECxno7LZPu",
        "outputId": "83f3ef0b-8779-4379-9bfd-5711376eb73f"
      },
      "id": "OBECxno7LZPu",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "UFicZvk-PJQb",
        "outputId": "15434701-e238-4d3f-ef91-8fc1e2fc6550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UFicZvk-PJQb",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wVqPcHeGCFHA",
        "outputId": "4728a02b-e0c5-4aa1-91cb-5a8aa2abc6f4"
      },
      "id": "wVqPcHeGCFHA",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 32  # Reduced initial channels\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 32, layers[0])  # Adjusted channels\n",
        "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2)  # Adjusted channels\n",
        "        self.layer3 = self._make_layer(block, 128, layers[2], stride=2)  # Adjusted channels\n",
        "        self.layer4 = self._make_layer(block, 256, layers[3], stride=2)  # Adjusted channels\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256 * block.expansion, num_classes)  # Adjusted to match reduced channels\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def resnet18_modified(num_classes=10):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-V9ikhBUP-e",
        "outputId": "66690b77-7554-42a1-c430-5064ea701478"
      },
      "id": "k-V9ikhBUP-e",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "            Conv2d-4           [-1, 32, 32, 32]           9,216\n",
            "       BatchNorm2d-5           [-1, 32, 32, 32]              64\n",
            "              ReLU-6           [-1, 32, 32, 32]               0\n",
            "            Conv2d-7           [-1, 32, 32, 32]           9,216\n",
            "       BatchNorm2d-8           [-1, 32, 32, 32]              64\n",
            "              ReLU-9           [-1, 32, 32, 32]               0\n",
            "       BasicBlock-10           [-1, 32, 32, 32]               0\n",
            "           Conv2d-11           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-12           [-1, 32, 32, 32]              64\n",
            "             ReLU-13           [-1, 32, 32, 32]               0\n",
            "           Conv2d-14           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-15           [-1, 32, 32, 32]              64\n",
            "             ReLU-16           [-1, 32, 32, 32]               0\n",
            "       BasicBlock-17           [-1, 32, 32, 32]               0\n",
            "           Conv2d-18           [-1, 64, 16, 16]          18,432\n",
            "      BatchNorm2d-19           [-1, 64, 16, 16]             128\n",
            "             ReLU-20           [-1, 64, 16, 16]               0\n",
            "           Conv2d-21           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-22           [-1, 64, 16, 16]             128\n",
            "           Conv2d-23           [-1, 64, 16, 16]           2,048\n",
            "      BatchNorm2d-24           [-1, 64, 16, 16]             128\n",
            "             ReLU-25           [-1, 64, 16, 16]               0\n",
            "       BasicBlock-26           [-1, 64, 16, 16]               0\n",
            "           Conv2d-27           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-28           [-1, 64, 16, 16]             128\n",
            "             ReLU-29           [-1, 64, 16, 16]               0\n",
            "           Conv2d-30           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 16, 16]             128\n",
            "             ReLU-32           [-1, 64, 16, 16]               0\n",
            "       BasicBlock-33           [-1, 64, 16, 16]               0\n",
            "           Conv2d-34            [-1, 128, 8, 8]          73,728\n",
            "      BatchNorm2d-35            [-1, 128, 8, 8]             256\n",
            "             ReLU-36            [-1, 128, 8, 8]               0\n",
            "           Conv2d-37            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
            "           Conv2d-39            [-1, 128, 8, 8]           8,192\n",
            "      BatchNorm2d-40            [-1, 128, 8, 8]             256\n",
            "             ReLU-41            [-1, 128, 8, 8]               0\n",
            "       BasicBlock-42            [-1, 128, 8, 8]               0\n",
            "           Conv2d-43            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-44            [-1, 128, 8, 8]             256\n",
            "             ReLU-45            [-1, 128, 8, 8]               0\n",
            "           Conv2d-46            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-47            [-1, 128, 8, 8]             256\n",
            "             ReLU-48            [-1, 128, 8, 8]               0\n",
            "       BasicBlock-49            [-1, 128, 8, 8]               0\n",
            "           Conv2d-50            [-1, 256, 4, 4]         294,912\n",
            "      BatchNorm2d-51            [-1, 256, 4, 4]             512\n",
            "             ReLU-52            [-1, 256, 4, 4]               0\n",
            "           Conv2d-53            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-54            [-1, 256, 4, 4]             512\n",
            "           Conv2d-55            [-1, 256, 4, 4]          32,768\n",
            "      BatchNorm2d-56            [-1, 256, 4, 4]             512\n",
            "             ReLU-57            [-1, 256, 4, 4]               0\n",
            "       BasicBlock-58            [-1, 256, 4, 4]               0\n",
            "           Conv2d-59            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-60            [-1, 256, 4, 4]             512\n",
            "             ReLU-61            [-1, 256, 4, 4]               0\n",
            "           Conv2d-62            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-63            [-1, 256, 4, 4]             512\n",
            "             ReLU-64            [-1, 256, 4, 4]               0\n",
            "       BasicBlock-65            [-1, 256, 4, 4]               0\n",
            "AdaptiveAvgPool2d-66            [-1, 256, 1, 1]               0\n",
            "           Linear-67                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 2,797,610\n",
            "Trainable params: 2,797,610\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 7.75\n",
            "Params size (MB): 10.67\n",
            "Estimated Total Size (MB): 18.44\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5077a13d-c1c3-4174-bb35-92dca22210f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5077a13d-c1c3-4174-bb35-92dca22210f5",
        "outputId": "40f5682b-c6d2-422a-a013-ee0e8b016e9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 1.3952, Train Accuracy: 48.66%, Test Accuracy: 52.09%, Time: 28.29s\n",
            "Epoch 2/10, Train Loss: 0.9405, Train Accuracy: 66.43%, Test Accuracy: 70.27%, Time: 30.34s\n",
            "Epoch 3/10, Train Loss: 0.7443, Train Accuracy: 73.97%, Test Accuracy: 74.26%, Time: 29.06s\n",
            "Epoch 4/10, Train Loss: 0.6301, Train Accuracy: 78.04%, Test Accuracy: 77.99%, Time: 32.03s\n",
            "Epoch 5/10, Train Loss: 0.5577, Train Accuracy: 80.42%, Test Accuracy: 79.76%, Time: 29.06s\n",
            "Epoch 6/10, Train Loss: 0.5014, Train Accuracy: 82.58%, Test Accuracy: 79.60%, Time: 28.60s\n",
            "Epoch 7/10, Train Loss: 0.4611, Train Accuracy: 84.12%, Test Accuracy: 84.25%, Time: 27.78s\n",
            "Epoch 8/10, Train Loss: 0.4209, Train Accuracy: 85.47%, Test Accuracy: 81.86%, Time: 28.82s\n",
            "Epoch 9/10, Train Loss: 0.3910, Train Accuracy: 86.36%, Test Accuracy: 82.89%, Time: 32.72s\n",
            "Epoch 10/10, Train Loss: 0.3654, Train Accuracy: 87.43%, Test Accuracy: 84.88%, Time: 29.82s\n"
          ]
        }
      ],
      "source": [
        "#training (verbose) on CIFAR10\n",
        "import time\n",
        "\n",
        "def train_model(model, trainloader, testloader, criterion, optimizer, num_epochs=10):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        for i, (images, labels) in enumerate(trainloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(trainloader)\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        model.eval()  # eval\n",
        "        with torch.no_grad():\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            for images, labels in testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = 100 * correct / total\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
        "              f'Train Loss: {train_loss:.4f}, '\n",
        "              f'Train Accuracy: {train_acc:.2f}%, '\n",
        "              f'Test Accuracy: {test_acc:.2f}%, '\n",
        "              f'Time: {elapsed_time:.2f}s')\n",
        "\n",
        "# Usage\n",
        "num_epochs = 10\n",
        "model = resnet18_modified().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_model(model, trainloader, testloader, criterion, optimizer, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "unpickle('./cifar_test_nolabels.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ITO6hGr2Iu4",
        "outputId": "9fece5fb-2b06-4d5e-a38c-352871fa5779"
      },
      "id": "0ITO6hGr2Iu4",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{b'data': array([[133, 136, 136, ..., 226, 225, 224],\n",
              "        [160, 177, 176, ...,  89,  89,  88],\n",
              "        [255, 255, 255, ..., 211, 213, 215],\n",
              "        ...,\n",
              "        [ 29,  29,  45, ..., 156, 155, 154],\n",
              "        [124, 123, 126, ...,  49,  49,  51],\n",
              "        [255, 255, 255, ..., 250, 251, 255]], dtype=uint8),\n",
              " b'ids': array([   0,    1,    2, ..., 9997, 9998, 9999])}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sanitycheck, CIFAR nolabel data is loading\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = unpickle('./cifar_test_nolabels.pkl')\n",
        "image_id = 1111 #change this to look at the image by id (goes 0 thru 9999)\n",
        "\n",
        "an_image = data[b'data'][image_id]\n",
        "an_image = an_image.reshape(3, 32, 32)\n",
        "an_image = an_image.transpose(1, 2, 0)\n",
        "\n",
        "plt.imshow(an_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "WXmGFXAE5Iov",
        "outputId": "e70fe8e3-e99a-4057-b0b2-9f322ad6c832"
      },
      "id": "WXmGFXAE5Iov",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the unlabeled data\n",
        "images = torch.tensor(data[b'data']).float()\n",
        "images = images.view(-1, 3, 32, 32)\n",
        "images = images / 255.0\n",
        "\n",
        "# Normalize images as done during training\n",
        "images = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(images)"
      ],
      "metadata": {
        "id": "--1e-pNuMj_W"
      },
      "id": "--1e-pNuMj_W",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Predict\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    images = images.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Save predictions to CSV\n",
        "predictions = predicted.cpu().numpy()\n",
        "ids = np.arange(len(predictions))\n",
        "submission = pd.DataFrame({'ID': ids, 'Label': predictions})\n",
        "submission.to_csv('cifar_predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "PLK-vrbQPqJD"
      },
      "id": "PLK-vrbQPqJD",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def resnet18_modified(num_classes=10):\n",
        "    return CustomResNet(BasicBlock, [3, 3, 3], num_classes=num_classes)\n",
        "\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ESZYQFp8XYP",
        "outputId": "c52a9f2a-3dba-4f21-85af-1624a77288bc"
      },
      "id": "1ESZYQFp8XYP",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "            Conv2d-7           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
            "              ReLU-9           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-10           [-1, 64, 32, 32]               0\n",
            "           Conv2d-11           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-12           [-1, 64, 32, 32]             128\n",
            "             ReLU-13           [-1, 64, 32, 32]               0\n",
            "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
            "             ReLU-16           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-17           [-1, 64, 32, 32]               0\n",
            "           Conv2d-18           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-19           [-1, 64, 32, 32]             128\n",
            "             ReLU-20           [-1, 64, 32, 32]               0\n",
            "           Conv2d-21           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-22           [-1, 64, 32, 32]             128\n",
            "             ReLU-23           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-24           [-1, 64, 32, 32]               0\n",
            "           Conv2d-25          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-26          [-1, 128, 16, 16]             256\n",
            "             ReLU-27          [-1, 128, 16, 16]               0\n",
            "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
            "           Conv2d-30          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-31          [-1, 128, 16, 16]             256\n",
            "             ReLU-32          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-33          [-1, 128, 16, 16]               0\n",
            "           Conv2d-34          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-35          [-1, 128, 16, 16]             256\n",
            "             ReLU-36          [-1, 128, 16, 16]               0\n",
            "           Conv2d-37          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-38          [-1, 128, 16, 16]             256\n",
            "             ReLU-39          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-40          [-1, 128, 16, 16]               0\n",
            "           Conv2d-41          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-42          [-1, 128, 16, 16]             256\n",
            "             ReLU-43          [-1, 128, 16, 16]               0\n",
            "           Conv2d-44          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-45          [-1, 128, 16, 16]             256\n",
            "             ReLU-46          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-47          [-1, 128, 16, 16]               0\n",
            "           Conv2d-48            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-49            [-1, 256, 8, 8]             512\n",
            "             ReLU-50            [-1, 256, 8, 8]               0\n",
            "           Conv2d-51            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-52            [-1, 256, 8, 8]             512\n",
            "           Conv2d-53            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-54            [-1, 256, 8, 8]             512\n",
            "             ReLU-55            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-56            [-1, 256, 8, 8]               0\n",
            "           Conv2d-57            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-58            [-1, 256, 8, 8]             512\n",
            "             ReLU-59            [-1, 256, 8, 8]               0\n",
            "           Conv2d-60            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-61            [-1, 256, 8, 8]             512\n",
            "             ReLU-62            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-63            [-1, 256, 8, 8]               0\n",
            "           Conv2d-64            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-65            [-1, 256, 8, 8]             512\n",
            "             ReLU-66            [-1, 256, 8, 8]               0\n",
            "           Conv2d-67            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-68            [-1, 256, 8, 8]             512\n",
            "             ReLU-69            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-70            [-1, 256, 8, 8]               0\n",
            "AdaptiveAvgPool2d-71            [-1, 256, 1, 1]               0\n",
            "           Linear-72                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 4,327,754\n",
            "Trainable params: 4,327,754\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 20.63\n",
            "Params size (MB): 16.51\n",
            "Estimated Total Size (MB): 37.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "images = torch.tensor(images)\n",
        "images = transform(images)\n",
        "\n",
        "# Since we don't have labels, using dummy labels for demonstration\n",
        "labels = torch.zeros(images.size(0), dtype=torch.long)\n",
        "\n",
        "# Create the DataLoader\n",
        "dataset = TensorDataset(images, labels)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Model, Loss, and Optimizer\n",
        "model = resnet18_modified().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, _) in enumerate(loader):\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.to(device))  # Using dummy labels here\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "zPbKju-xK5TC"
      },
      "id": "zPbKju-xK5TC",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}